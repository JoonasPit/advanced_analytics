{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3da5832e-69e5-440d-b6ad-b584d79935fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-24 17:57:14.103846: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-24 17:57:14.113297: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1732463834.124478   21855 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1732463834.127972   21855 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-24 17:57:14.139532: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from urllib import request\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from io import StringIO\n",
    "from collections import Counter\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "import nltk\n",
    "from __future__ import print_function\n",
    "from keras.layers import Dense, Activation, SimpleRNN, LSTM\n",
    "from keras.models import Sequential\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import wordcloud as w\n",
    "import matplotlib.pyplot as plot\n",
    "import torch\n",
    "from transformers import  BartTokenizer, TFBartForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8315135-1231-4296-89ce-db618b8a38de",
   "metadata": {},
   "outputs": [],
   "source": [
    "shelley_frank = request.urlopen('https://www.gutenberg.org/cache/epub/84/pg84.txt').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32edb3cc-6664-47d5-860b-5e3548b2e2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Project Gutenberg eBook of Frankenstein; Or, The Modern Prometheus\n",
      "    \n",
      "This ebook is for the \n"
     ]
    }
   ],
   "source": [
    "shelley_frank = shelley_frank.decode('utf-8-sig')\n",
    "print(shelley_frank[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09e85a4f-09df-47b1-8f97-202a9c378970",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_start = 'You will rejoice'\n",
    "word_index = shelley_frank.find(actual_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e288336b-6c18-46e3-8782-c66115e02a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if word_index != -1:\n",
    "    shelley_frank = shelley_frank[word_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8b0754c-d990-4d5c-b383-fdcbf10c450c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you will rejoice to hear that no disaster has accompanied the commencement of an enterprise which yo\n"
     ]
    }
   ],
   "source": [
    "shelley_frank = re.sub(r'—', ' ', shelley_frank.lower())\n",
    "shelley_frank = shelley_frank.replace('project gutenberg', '')\n",
    "shelley_frank = nltk.word_tokenize(shelley_frank)\n",
    "shelley_frank = ' '.join(shelley_frank)  \n",
    "\n",
    "# Ensure space after punctuation if it's missing\n",
    "print(shelley_frank[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7976306-1b83-4e23-b136-d0679c13a91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you will rejoice to hear that no disaster has accompanied the commencement of an enterprise which you have regarded with such evil forebodings. i arrived here yesterday, and my first task is to assure my dear sister of my welfare and increasing confidence in the success of my undertaking. i am already far north of london, and as i walk in the streets of petersburgh, i feel a cold northern breeze play upon my cheeks, which braces my nerves and fills me with delight. do you understand this feeling? this breeze, which has travelled from the regions towards which i am advancing, gives me a foretaste of those icy climes. inspirited by this wind of promise, my daydreams become more fervent and vivid. i try in vain to be persuaded that the pole is the seat of frost and desolation; it ever presents itself to my imagination as the region of beauty and delight. there, margaret, the sun is for ever visible, its broad disk just skirting the horizon and diffusing a perpetual splendour. there for wi\n"
     ]
    }
   ],
   "source": [
    "shelley_frank = re.sub(r'[^a-zA-Z.,!?; ]', '', shelley_frank)\n",
    "shelley_frank = re.sub(r'([.,!?;])', r'\\1 ', shelley_frank)\n",
    "shelley_frank = re.sub(r'\\s+([.,!?;])', r'\\1', shelley_frank)\n",
    "shelley_frank = re.sub(r'\\s+', ' ', shelley_frank) \n",
    "print(shelley_frank[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "740019aa-d2ad-4797-a25d-2fea45c70cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./shelley.txt', 'w') as output_file:\n",
    "    output_file.write(shelley_frank)\n",
    "\n",
    "with open('./shelley.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "\n",
    "sentences = re.split(r'\\.|\\n', text)  # This will split by periods and newlines\n",
    "sentences = [sentence.strip() for sentence in sentences if sentence.strip()]\n",
    "\n",
    "with open('./shelley_processed.txt', 'w') as file:\n",
    "    for sentence in sentences:\n",
    "        file.write(sentence + '\\n')\n",
    "\n",
    "# Print the number of lines\n",
    "#print(len(lines))  # Make sure it prints a value greater than 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c68cd444-67d0-4820-a1bd-fbab9d195ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 most frequent words:\n",
      "'the': 4373\n",
      "'and': 3040\n",
      "'i': 2850\n",
      "'of': 2757\n",
      "'to': 2174\n",
      "'my': 1776\n",
      "'a': 1449\n",
      "'in': 1186\n",
      "'that': 1033\n",
      "'was': 1023\n",
      "'me': 867\n",
      "'with': 712\n",
      "'but': 691\n",
      "'had': 686\n",
      "'you': 645\n",
      "'he': 610\n",
      "'not': 587\n",
      "'which': 565\n",
      "'it': 559\n",
      "'as': 538\n",
      "'his': 535\n",
      "'for': 523\n",
      "'by': 485\n",
      "'on': 471\n",
      "'this': 444\n",
      "'from': 400\n",
      "'be': 376\n",
      "'her': 373\n",
      "'have': 371\n",
      "'when': 329\n",
      "'is': 328\n",
      "'at': 328\n",
      "'were': 308\n",
      "'your': 261\n",
      "'she': 256\n",
      "'or': 252\n",
      "'him': 222\n",
      "'all': 217\n",
      "'an': 216\n",
      "'if': 215\n",
      "'they': 212\n",
      "'so': 211\n",
      "'one': 208\n",
      "'will': 201\n",
      "'could': 198\n",
      "'are': 197\n",
      "'been': 190\n",
      "'their': 186\n",
      "'we': 183\n",
      "'would': 183\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import string\n",
    "\n",
    "def count_top_words_in_file(file_path, top_n=50):\n",
    "    # Open the file in read mode\n",
    "    with open(file_path, 'r') as file:\n",
    "        # Read the file content\n",
    "        text = file.read().lower()  # convert to lowercase to count case-insensitive\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Split the text into words\n",
    "    words = text.split()\n",
    "    \n",
    "    # Use Counter to count occurrences of each word\n",
    "    word_counts = Counter(words)\n",
    "    \n",
    "    # Get the top N most common words\n",
    "    most_common_words = word_counts.most_common(top_n)\n",
    "    \n",
    "    return most_common_words\n",
    "\n",
    "# Specify the file path\n",
    "file_path = 'shelley_processed.txt'\n",
    "\n",
    "# Get the top 10 most frequent words\n",
    "top_words = count_top_words_in_file(file_path, top_n=50)\n",
    "\n",
    "# Print the top 10 most frequent words\n",
    "print(\"Top 10 most frequent words:\")\n",
    "for word, count in top_words:\n",
    "    print(f\"'{word}': {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "385313f2-e52a-4ba7-9f30-eff4003b581a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "CPU times: user 1.66 s, sys: 464 ms, total: 2.12 s\n",
      "Wall time: 201 ms\n",
      "mkdir: cannot create directory ‘./transf_shelley’: File exists\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./transf_shelley/tokenizer_config.json',\n",
       " './transf_shelley/special_tokens_map.json',\n",
       " './transf_shelley/tokenizer.json')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tokenizers import ByteLevelBPETokenizer, trainers\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "from tokenizers.implementations import ByteLevelBPETokenizer\n",
    "from tokenizers.processors import BertProcessing\n",
    "\n",
    "bpe_tokenizer = ByteLevelBPETokenizer()\n",
    "special_tokens = [\"<pad>\", \"<s>\", \"</s>\"]\n",
    "trainer = trainers.BpeTrainer(vocab_size=20000, min_frequency=2, special_tokens=special_tokens)\n",
    "\n",
    "%time bpe_tokenizer.train(files='./shelley_processed.txt', vocab_size=20000, min_frequency=2, special_tokens = special_tokens)\n",
    "\n",
    "!mkdir ./transf_shelley\n",
    "model_name = './transf_shelley'\n",
    "bpe_tokenizer.save_model(model_name)\n",
    "# Save the tokenizer using save_pretrained to create the necessary files\n",
    "# Wrap the ByteLevelBPETokenizer with PreTrainedTokenizerFast\n",
    "print(bpe_tokenizer.get_vocab()[\"<pad>\"])\n",
    "tokenizer = PreTrainedTokenizerFast(tokenizer_object=bpe_tokenizer)\n",
    "tokenizer.pad_token = \"<pad>\"\n",
    "tokenizer.bos_token = \"<s>\"\n",
    "tokenizer.eos_token = \"</s>\"\n",
    "#tokenizer.decoder_start_token_id = tokenizer.pad_token_id  # Same as pad token\n",
    "# Save the tokenizer using save_pretrained to create the necessary files\n",
    "tokenizer.save_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da329322-fc82-4030-9da3-9696565a862b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ġempty': 6702,\n",
       " 'ouble': 3877,\n",
       " 'Ġabsolute': 5595,\n",
       " 'Ġmockery': 3781,\n",
       " 'Ġser': 2633,\n",
       " 'ted': 472,\n",
       " 'Ġobstructed': 7385,\n",
       " 'Ġbeloved': 1476,\n",
       " 'Ġagonies': 4883,\n",
       " 'Ġsuperior': 2753,\n",
       " 'Ġwatched': 4637,\n",
       " 'Ġben': 5080,\n",
       " 'Ġnecessary': 1885,\n",
       " 'man': 1153,\n",
       " 'utenberg': 1590,\n",
       " 'Ġtaught': 3217,\n",
       " 'aculous': 6802,\n",
       " 'oned': 3888,\n",
       " 'Ġescap': 1964,\n",
       " 'Ġtravels': 4739,\n",
       " 'Ġfrequ': 3152,\n",
       " 'Ġarranged': 4787,\n",
       " 'Ġnur': 2285,\n",
       " 'Ġdoubtless': 3405,\n",
       " 'omet': 848,\n",
       " 'Ġstreamed': 7001,\n",
       " 'Ġunderstanding': 4144,\n",
       " 'Ġown': 606,\n",
       " 'Ġbent': 2805,\n",
       " 'Ġroared': 5388,\n",
       " 'icable': 6263,\n",
       " 'Ġhighly': 4726,\n",
       " 'Ġhuman': 825,\n",
       " 'ote': 3031,\n",
       " 'Ġask': 2653,\n",
       " 'Ġder': 3520,\n",
       " 'Ġwater': 1797,\n",
       " 'Ġtrust': 3618,\n",
       " 'beaufort': 7476,\n",
       " 'Ġprecipitate': 7089,\n",
       " 'Ġh': 278,\n",
       " 'Ġruined': 5593,\n",
       " 'owed': 804,\n",
       " 'omena': 6257,\n",
       " 'Ġsupple': 6753,\n",
       " 'Ġresembling': 7310,\n",
       " 'Ġobtain': 2116,\n",
       " 'Ġshowed': 3285,\n",
       " 'Ġfishermen': 5925,\n",
       " 'Ġexamining': 5629,\n",
       " 'Ġven': 1608,\n",
       " 'Ġwonder': 1018,\n",
       " 'irer': 4054,\n",
       " 'Ġlecture': 4235,\n",
       " 'Ġwalls': 4887,\n",
       " 'Ġomnipotence': 7419,\n",
       " 'ardon': 3965,\n",
       " 'Ġthom': 6225,\n",
       " 'aster': 1839,\n",
       " 'Ġcongratulatory': 7615,\n",
       " 'Ġdemon': 4447,\n",
       " 'Ġacquirement': 7457,\n",
       " 'r': 84,\n",
       " 'Ġcas': 6167,\n",
       " 'Ġregions': 3674,\n",
       " 'Ġprey': 2698,\n",
       " 'Ġspot': 1662,\n",
       " 'Ġsolicited': 7317,\n",
       " 'ised': 891,\n",
       " 'Ġtwo': 1190,\n",
       " 'saville': 5919,\n",
       " 'Ġexpiration': 6544,\n",
       " 'mate': 4329,\n",
       " 'Ġplants': 6676,\n",
       " 'Ġbarrier': 4925,\n",
       " 'Ġmutiny': 7129,\n",
       " 'Ġcity': 2277,\n",
       " 'Ġor': 433,\n",
       " 'enev': 859,\n",
       " 'Ġpas': 554,\n",
       " 'Ġsending': 6397,\n",
       " 'Ġerrone': 7462,\n",
       " 'Ġfired': 5345,\n",
       " 'Ġugly': 4892,\n",
       " 'por': 5004,\n",
       " 'Ġbelie': 893,\n",
       " 'cl': 693,\n",
       " 'Ġexhibited': 3175,\n",
       " 'eaks': 6449,\n",
       " 'Ġty': 2983,\n",
       " 'Ġlow': 2183,\n",
       " 'Ġperpet': 2943,\n",
       " 'Ġmusic': 3766,\n",
       " 'Ġwilds': 5587,\n",
       " 'Ġomnip': 4293,\n",
       " 'Ġheavenly': 4687,\n",
       " 'Ġimag': 979,\n",
       " 'Ġtremb': 1958,\n",
       " 'Ġdomes': 7157,\n",
       " 'Ġbroke': 4138,\n",
       " 'Ġundisturbed': 5727,\n",
       " 'Ġearlier': 5822,\n",
       " 'itous': 6220,\n",
       " 'Ġexception': 7065,\n",
       " 'Ġflow': 2717,\n",
       " 'Ġbranches': 2490,\n",
       " 'Ġmankind': 2546,\n",
       " 'Ġdraught': 7063,\n",
       " 'Ġmorning': 1112,\n",
       " 'Ġdaunt': 6189,\n",
       " 'Ġprotectors': 2355,\n",
       " 'Ġleast': 2449,\n",
       " 'uteness': 6922,\n",
       " 'ilitated': 6394,\n",
       " 'Ġinj': 2522,\n",
       " 'cent': 2960,\n",
       " 'Ġdetestation': 5828,\n",
       " 'Ġhumankind': 6708,\n",
       " 'resent': 4493,\n",
       " 'Ġfashion': 4377,\n",
       " 'Ġtried': 2166,\n",
       " 'isible': 5110,\n",
       " 'Ġfeeble': 5673,\n",
       " 'itting': 2321,\n",
       " 'Ġconnection': 5729,\n",
       " 'otected': 5168,\n",
       " 'verance': 6310,\n",
       " 'ħ': 230,\n",
       " 'Ġlock': 5307,\n",
       " 'Ġjoy': 933,\n",
       " 'eneva': 1148,\n",
       " 'is': 285,\n",
       " 'farewell': 4311,\n",
       " 'cial': 5323,\n",
       " 'Ġmisfortun': 1208,\n",
       " 'Ġdisplaying': 4215,\n",
       " 'ameless': 6380,\n",
       " 'Ġrocky': 7107,\n",
       " 'Ġcountryman': 6735,\n",
       " 'Ġexhaust': 3135,\n",
       " 'avourable': 6877,\n",
       " 'Ġenraptured': 7643,\n",
       " 'itional': 3357,\n",
       " 'iet': 2616,\n",
       " 'Ġneither': 3314,\n",
       " 'Ġmass': 4360,\n",
       " 'Ã': 130,\n",
       " 'Ġharm': 2810,\n",
       " 'Ġfreed': 3422,\n",
       " 'Ġnoble': 2436,\n",
       " 'Ġamong': 934,\n",
       " 'Ġfro': 2394,\n",
       " 'Ġcauses': 4162,\n",
       " 'Ġoce': 2267,\n",
       " 'Ġdespair': 948,\n",
       " 'able': 435,\n",
       " 'Ġcr': 1354,\n",
       " 'Ġmus': 2384,\n",
       " 'Ġacquired': 5518,\n",
       " 'ldom': 3554,\n",
       " 'cess': 1344,\n",
       " 'estion': 6408,\n",
       " 'Ġlangu': 1323,\n",
       " 'Ġmenaced': 6789,\n",
       " 'Ġrestored': 2026,\n",
       " 'Ġwreck': 4201,\n",
       " 'Ġsweetness': 5550,\n",
       " 'Ġdisp': 1657,\n",
       " 'Ġdifference': 4135,\n",
       " 'Æ': 133,\n",
       " 'dep': 5986,\n",
       " 'dest': 5983,\n",
       " 'Ġpreserve': 3647,\n",
       " 'Ġpec': 3007,\n",
       " 'Ġmedic': 7096,\n",
       " 'Ġtravellers': 7109,\n",
       " 'Ġaccused': 3323,\n",
       " 'Ġmanoir': 6455,\n",
       " 'Ġflit': 6790,\n",
       " 'Ġwill': 459,\n",
       " 'Ġplacing': 6640,\n",
       " 'Ġmor': 960,\n",
       " 'Ġfirm': 2118,\n",
       " 'ises': 5107,\n",
       " 'Ġwhat': 610,\n",
       " 'in': 274,\n",
       " 'Ġterms': 1334,\n",
       " 'Ġtransported': 4902,\n",
       " 'Ġquickly': 1458,\n",
       " 'Ġdiscoveries': 3393,\n",
       " 'Ġexc': 896,\n",
       " 'Ġresided': 4588,\n",
       " 'Ġhere': 1259,\n",
       " 'Ġfo': 745,\n",
       " 'never': 5354,\n",
       " 'sec': 5166,\n",
       " 'Ġarabic': 7066,\n",
       " 'Ġbound': 1100,\n",
       " 'Ġcottages': 4121,\n",
       " 'chem': 4963,\n",
       " 'Ġambition': 3064,\n",
       " 'Ġsurrounding': 6970,\n",
       " 'Ġenemy': 1588,\n",
       " 'Ġf': 275,\n",
       " 'Ġfinally': 7042,\n",
       " 'Ġsea': 1181,\n",
       " 'ok': 6031,\n",
       " 'Ġguided': 4627,\n",
       " 'Ġang': 1264,\n",
       " 'Ġhope': 936,\n",
       " 'Ġshutters': 7103,\n",
       " 'Ġenjoined': 7645,\n",
       " 'Ġwhither': 3920,\n",
       " 'itary': 2518,\n",
       " 'Ġminute': 2910,\n",
       " 'Ġperth': 5290,\n",
       " 'Ġshunned': 5937,\n",
       " 'astly': 5318,\n",
       " 'Ġplain': 2222,\n",
       " 'Ġstopped': 5896,\n",
       " 'æ': 165,\n",
       " 'Ġirish': 6903,\n",
       " 'ec': 1244,\n",
       " 'Ġcon': 354,\n",
       " 'Ġspec': 5271,\n",
       " 'Ġconsented': 4174,\n",
       " 'Ġthus': 902,\n",
       " 'Ġunmingled': 5262,\n",
       " 'ving': 785,\n",
       " 'Ġproduced': 2357,\n",
       " 'Ġmurdered': 1730,\n",
       " 'arm': 951,\n",
       " 'Ġimb': 3613,\n",
       " 'Ġconfused': 3657,\n",
       " 'Ġthr': 821,\n",
       " 'formed': 1940,\n",
       " 'Ġtreasures': 5831,\n",
       " 'Ġexer': 2663,\n",
       " 'olerable': 5296,\n",
       " 'Ġsave': 3294,\n",
       " 'Ġme': 321,\n",
       " 'Ġgladness': 5753,\n",
       " 'angers': 2859,\n",
       " 'Ġsincerely': 3115,\n",
       " 'Ġmerits': 5625,\n",
       " 'felix': 2313,\n",
       " 'ting': 1636,\n",
       " 'Ġremembered': 2348,\n",
       " 'wind': 4342,\n",
       " 'Ġstony': 6357,\n",
       " 'Ġletter': 1027,\n",
       " 'Ġprotect': 1679,\n",
       " 'Ġdreadful': 2473,\n",
       " 'Ġinterpreted': 7533,\n",
       " 'Ġbeginning': 2933,\n",
       " 'getables': 5538,\n",
       " '®': 109,\n",
       " 'road': 3941,\n",
       " 'Ġyears': 1010,\n",
       " 'used': 1753,\n",
       " 'Ġpresent': 987,\n",
       " 'es': 286,\n",
       " 'Ġreceiving': 3918,\n",
       " 'Ġlesson': 6961,\n",
       " 'Ġsurpassing': 7530,\n",
       " 'Ġdim': 3248,\n",
       " 'Ġpractical': 5802,\n",
       " 'Ġcarefully': 5521,\n",
       " 'ians': 6012,\n",
       " 'Ġless': 1510,\n",
       " 'Ġcompanion': 1312,\n",
       " 'Ġfour': 3880,\n",
       " 'Ġauth': 3859,\n",
       " 'Ġuniversity': 3460,\n",
       " 'Ġsir': 3226,\n",
       " 'Ġdeclare': 5825,\n",
       " '¾': 125,\n",
       " 'Ġespeci': 3823,\n",
       " 'ener': 1065,\n",
       " 'Ġoverfl': 4026,\n",
       " 'Ġglimmer': 7453,\n",
       " 'itated': 2083,\n",
       " 'Ġadvent': 4697,\n",
       " 'Ġborn': 4383,\n",
       " 'copyright': 3801,\n",
       " 'Ġpronouncing': 7250,\n",
       " 'Ġdoing': 3071,\n",
       " 'V': 56,\n",
       " 'Ġsum': 1363,\n",
       " 'Ġrest': 720,\n",
       " 'Ġextinguished': 3354,\n",
       " 'fice': 3835,\n",
       " 'Ġverd': 4911,\n",
       " 'Ġdec': 1230,\n",
       " 'Ġcom': 440,\n",
       " 'Ġpiercing': 7427,\n",
       " 'Ġwww': 2991,\n",
       " 'Ġspare': 5269,\n",
       " 'unged': 5325,\n",
       " 'ception': 2894,\n",
       " 'Ġirrevoc': 7242,\n",
       " 'ost': 915,\n",
       " 'Ġcomputer': 7445,\n",
       " 'liance': 3950,\n",
       " 'sw': 1346,\n",
       " 'Ġtempt': 5039,\n",
       " 'Ġcondemned': 2602,\n",
       " 'ning': 677,\n",
       " 'Ġham': 6259,\n",
       " 'Ġgent': 983,\n",
       " 'Ġsorrowful': 3384,\n",
       " 'Ġcrown': 5542,\n",
       " 'Ġsaved': 3295,\n",
       " 'Ġoccupation': 3369,\n",
       " 'Ġthunder': 2645,\n",
       " 'Ġlanguor': 5540,\n",
       " 'Ġglut': 5481,\n",
       " 'Ġbrothers': 4116,\n",
       " 'Ġnursed': 4811,\n",
       " 'Ġsaw': 673,\n",
       " 'Ġeffort': 2908,\n",
       " 'Ġrepaid': 6623,\n",
       " 'Ġsolely': 7004,\n",
       " 'Ġwhate': 6279,\n",
       " 'Ġmule': 6773,\n",
       " 'Ġhidden': 7015,\n",
       " 'igators': 5361,\n",
       " 'Ġfra': 6145,\n",
       " 'Ġreturned': 1274,\n",
       " 'ending': 5267,\n",
       " 'Ġbarren': 5599,\n",
       " 'Ġguitar': 4628,\n",
       " 'Ġinterrupted': 3791,\n",
       " 'Ġprolong': 3601,\n",
       " 'Ġturk': 2483,\n",
       " 'Ġwreak': 4819,\n",
       " 'Ġimper': 4041,\n",
       " 'ask': 1599,\n",
       " 'Ġchain': 6470,\n",
       " 'Ġdaily': 3154,\n",
       " 'Ġsit': 1698,\n",
       " 'Ġbre': 1761,\n",
       " 'spect': 1798,\n",
       " 'Ġvice': 3046,\n",
       " 'Ġgovernment': 4873,\n",
       " 'Ġdirectly': 6901,\n",
       " 'Ġdated': 5099,\n",
       " 'ughter': 7026,\n",
       " 'Ġforci': 5185,\n",
       " 'Ġbusy': 3423,\n",
       " 'Ġinfall': 6809,\n",
       " 'Ġmorrow': 4359,\n",
       " 'Ġinconceivable': 7340,\n",
       " 'Ġnove': 4538,\n",
       " 'Ġstrang': 5358,\n",
       " 'Ġfeverish': 4183,\n",
       " 'Ġharbour': 5688,\n",
       " 'Ġuseful': 4724,\n",
       " 'ter': 368,\n",
       " 'ething': 1935,\n",
       " 'Ġwarranty': 7417,\n",
       " 'ouses': 3980,\n",
       " 'brated': 5974,\n",
       " 'Ġargument': 7214,\n",
       " 'Ġdoes': 1925,\n",
       " 'Ġmalignity': 3410,\n",
       " 'Ġcommon': 4057,\n",
       " 'Ġleaving': 4657,\n",
       " 'z': 92,\n",
       " 'Ġsens': 820,\n",
       " 'em': 423,\n",
       " 'pport': 5209,\n",
       " 'Ġliterary': 2250,\n",
       " 'Ġstand': 5204,\n",
       " 'Ġaccomplish': 5819,\n",
       " 'iate': 6011,\n",
       " 'Ġshock': 3578,\n",
       " 'p': 82,\n",
       " 'Ġthence': 4034,\n",
       " 'Ġswim': 6824,\n",
       " 'Ġprecept': 6618,\n",
       " 'Ġsom': 1901,\n",
       " 'Ġattitude': 6598,\n",
       " 'Ġspared': 3983,\n",
       " \"'\": 9,\n",
       " 'Ġmuscles': 5685,\n",
       " 'Ġug': 3557,\n",
       " 'Ġenthusi': 2154,\n",
       " 'aying': 2418,\n",
       " 'Ġshame': 6387,\n",
       " 'Ġprepare': 3400,\n",
       " 'llow': 696,\n",
       " 'Ġdiscover': 1411,\n",
       " 'Ġintersper': 6765,\n",
       " 'Ġbeat': 3266,\n",
       " 'Ġexper': 5329,\n",
       " 'Ġoperations': 4877,\n",
       " 'Ġcompassion': 2367,\n",
       " 'ia': 3476,\n",
       " 'lete': 1956,\n",
       " 'Ġdearly': 5431,\n",
       " 'ick': 743,\n",
       " 'Ġpassions': 2451,\n",
       " 'hear': 6103,\n",
       " 'Ġhuts': 7261,\n",
       " 'Ġrepentance': 7394,\n",
       " 'Ġbody': 1587,\n",
       " 'Ġrepaired': 6624,\n",
       " 'Ġopinions': 7401,\n",
       " 'Ġendowed': 4560,\n",
       " 'Ġsatisfied': 2481,\n",
       " 'Ġfinal': 7041,\n",
       " 'uten': 1390,\n",
       " 'Ġnook': 6243,\n",
       " 'irium': 3560,\n",
       " 'Ġsingularly': 7413,\n",
       " 'Ġflowers': 4227,\n",
       " 'Ġwitness': 2265,\n",
       " 'Ġsim': 2169,\n",
       " 'Ġmagnificence': 7196,\n",
       " 'Ġoxfor': 3872,\n",
       " 'Ġconqu': 5196,\n",
       " 'Ġapprove': 6838,\n",
       " 'Ġraven': 6426,\n",
       " 'Ġexpressed': 1444,\n",
       " 'round': 1498,\n",
       " 'Ġinter': 917,\n",
       " 'ection': 776,\n",
       " 'Ġtold': 2174,\n",
       " 'Ġire': 4356,\n",
       " 'Ġbeg': 892,\n",
       " 'Ġbore': 3236,\n",
       " 'acity': 2891,\n",
       " 'Ġstruggle': 4861,\n",
       " 'Ġsinks': 7153,\n",
       " 'Ġhistory': 1780,\n",
       " 'Ġhairs': 5707,\n",
       " 'eded': 6124,\n",
       " 'Ġanalys': 7616,\n",
       " 'Ġaside': 4450,\n",
       " 'umption': 5293,\n",
       " 'Ġease': 5134,\n",
       " 'Ġdoting': 6188,\n",
       " 'Ġinnoc': 1132,\n",
       " 'Ġsqual': 4366,\n",
       " 'Ġturkish': 7150,\n",
       " 'Ġbodily': 4706,\n",
       " 'Ġenable': 5311,\n",
       " 'Ġgenerous': 3710,\n",
       " 'Ġthink': 1296,\n",
       " 'xture': 4759,\n",
       " 'lic': 969,\n",
       " 'Ġutterance': 5554,\n",
       " 'Ġruled': 7506,\n",
       " 'Ġarrived': 1336,\n",
       " 'Ġconsumed': 4776,\n",
       " 'Ġblunt': 6692,\n",
       " 'Ġrich': 5251,\n",
       " 'om': 301,\n",
       " 'Ġallusion': 6465,\n",
       " 'Ġoxford': 4294,\n",
       " 'duction': 4257,\n",
       " 'Ġbec': 600,\n",
       " 'Ġspectre': 5854,\n",
       " 'Ġportion': 3254,\n",
       " 'Ġenem': 1306,\n",
       " 'Ġtalking': 7405,\n",
       " 'Ġsource': 3874,\n",
       " 'arded': 5249,\n",
       " 'Ġchast': 6471,\n",
       " 'inal': 2393,\n",
       " 'Ġfare': 5074,\n",
       " 'Ġfurniture': 7481,\n",
       " 'Ġparagraphs': 5669,\n",
       " 'Ġphilosopher': 3131,\n",
       " 'Ġonline': 5179,\n",
       " 'Ġintercept': 6764,\n",
       " 'mency': 4995,\n",
       " 'over': 6034,\n",
       " 'j': 76,\n",
       " 'lands': 6724,\n",
       " 'Ġprob': 2306,\n",
       " 'Ġtrack': 5320,\n",
       " 'oded': 3646,\n",
       " 'Ġsaf': 1267,\n",
       " 'Ġdeclared': 5826,\n",
       " 'use': 2061,\n",
       " 'Ġchattered': 6474,\n",
       " 'Ġavail': 3732,\n",
       " 'wise': 2979,\n",
       " 'Ġcontain': 4022,\n",
       " 'idence': 1435,\n",
       " 'Ġhell': 1910,\n",
       " 'ix': 2494,\n",
       " 'Ġadmirable': 5638,\n",
       " 'Ġposs': 775,\n",
       " 'Ġinterven': 6762,\n",
       " 'one': 517,\n",
       " 'ounix': 4122,\n",
       " 'itter': 1101,\n",
       " 'Ġenchant': 3612,\n",
       " 'Ġmethod': 3817,\n",
       " 'enes': 1979,\n",
       " 'Ġreason': 1563,\n",
       " 'Ġrelieve': 2931,\n",
       " 'Ġafternoon': 7656,\n",
       " 'ingly': 1508,\n",
       " 'rived': 2189,\n",
       " 'Ġmighty': 2318,\n",
       " 'ndrous': 2995,\n",
       " 'Ġtim': 6081,\n",
       " 'Ġsimple': 3430,\n",
       " 'anvert': 6230,\n",
       " 'Ġcomplying': 5632,\n",
       " 'Ġrap': 1519,\n",
       " 'Ġresolution': 3105,\n",
       " 'Ġthrew': 2282,\n",
       " 'Ġcontinued': 1215,\n",
       " 'cribed': 4654,\n",
       " 'presently': 3812,\n",
       " 'Ġshine': 5224,\n",
       " 'Ġener': 6510,\n",
       " 'iculate': 4427,\n",
       " 'Ġperceived': 1439,\n",
       " 'Ġliter': 1991,\n",
       " 'besides': 4287,\n",
       " 'Ġavalanche': 4288,\n",
       " 'Ġrus': 1921,\n",
       " 'so': 642,\n",
       " 'Ġcons': 586,\n",
       " 'Ġelse': 7268,\n",
       " 'ave': 774,\n",
       " 'Ġforward': 2187,\n",
       " 'Ġpartiality': 7658,\n",
       " 'Ġen': 468,\n",
       " 'Ġand': 279,\n",
       " 'Ġrise': 2847,\n",
       " 'this': 765,\n",
       " 'Ġstrove': 5207,\n",
       " 'Ġcoars': 6556,\n",
       " 'Ġnonpro': 6245,\n",
       " 'Ġgrat': 2119,\n",
       " 'Ġresolved': 1279,\n",
       " 'ead': 2613,\n",
       " 'urable': 4441,\n",
       " 'Ġwoe': 3099,\n",
       " 'Ġdevouring': 5509,\n",
       " 'Ġjur': 3608,\n",
       " 'form': 1091,\n",
       " 'ps': 1247,\n",
       " 'Ġscientific': 5923,\n",
       " 'Ġlost': 1207,\n",
       " 'Ġfix': 3322,\n",
       " 'Ġgroaned': 7467,\n",
       " 'ear': 419,\n",
       " 'Ġscattered': 4574,\n",
       " 'H': 42,\n",
       " 'Ġpermit': 4141,\n",
       " 'rain': 3846,\n",
       " 'Ġdiff': 953,\n",
       " 'Ġclosely': 7056,\n",
       " 'Ġear': 719,\n",
       " 'Ġsympathies': 4699,\n",
       " 'ught': 1820,\n",
       " 'Ġthings': 2520,\n",
       " 'alth': 1394,\n",
       " 'Ġprom': 962,\n",
       " 'Ġfelix': 1125,\n",
       " 'Ġadv': 1188,\n",
       " 'Ġwhy': 1391,\n",
       " 'Ġgain': 3033,\n",
       " 'Ġfil': 3234,\n",
       " 'Ġtortured': 4734,\n",
       " 'Ġimmense': 4153,\n",
       " 'Ġine': 3257,\n",
       " 'Ġremembrance': 2741,\n",
       " 'Ġfa': 611,\n",
       " 'Ġwrinkled': 5496,\n",
       " '4': 22,\n",
       " 'athed': 4367,\n",
       " 'belief': 6783,\n",
       " 'ŀ': 255,\n",
       " 'Ġrelease': 7492,\n",
       " 'Ġwhispered': 4918,\n",
       " 'Ġrocks': 5666,\n",
       " 'alities': 2829,\n",
       " 'angu': 1270,\n",
       " 'onpro': 6176,\n",
       " 'Ġinstant': 1333,\n",
       " 'Ġfeet': 2297,\n",
       " 'Ġperplexed': 7639,\n",
       " 'Ġunfortunate': 2149,\n",
       " 'Ġmistaken': 3738,\n",
       " 'Ġoriental': 7174,\n",
       " 'Ġsouthern': 5459,\n",
       " 'Ġcope': 6817,\n",
       " 'Ġkissed': 3994,\n",
       " 'Ġcredit': 3804,\n",
       " 'Ġlie': 2840,\n",
       " 'Ġburned': 5652,\n",
       " 'Ġinfant': 3106,\n",
       " 'asburgh': 4408,\n",
       " 'ton': 2620,\n",
       " 'Ġfeels': 6548,\n",
       " 'Ġreasoning': 4733,\n",
       " 'Ġplay': 1533,\n",
       " 'zy': 3852,\n",
       " 'Ġscent': 6591,\n",
       " 'Ġauthor': 3779,\n",
       " 'cience': 1185,\n",
       " 'Ġrace': 3591,\n",
       " 'Ġver': 3853,\n",
       " 'Ġhal': 6258,\n",
       " 'Ġinf': 999,\n",
       " 'Ġsails': 7034,\n",
       " 'Ġlover': 3069,\n",
       " 'ength': 1385,\n",
       " 'Ġfanned': 7256,\n",
       " 'Ġlarge': 3020,\n",
       " 'aged': 1443,\n",
       " 'lizabeth': 682,\n",
       " 'Ġrecollections': 7023,\n",
       " 'Ġabandon': 7383,\n",
       " 'Ġoverhung': 5821,\n",
       " 'ree': 629,\n",
       " 'Ġbal': 3883,\n",
       " 'Ġinher': 5129,\n",
       " 'Ġcontinue': 3351,\n",
       " 'Ġcapacity': 5539,\n",
       " 'Ġmach': 3868,\n",
       " 'Ġfresh': 2509,\n",
       " 'Ġberries': 3514,\n",
       " 'Ġmade': 778,\n",
       " 'Ġobli': 2115,\n",
       " 'vil': 5025,\n",
       " 'ustri': 3990,\n",
       " 'Ġsex': 6395,\n",
       " 'Ġworked': 3077,\n",
       " 'Ġadventurous': 7459,\n",
       " 'versed': 2827,\n",
       " 'great': 4976,\n",
       " 'Ġconfirmed': 3169,\n",
       " 'Ġcomrades': 7638,\n",
       " 'ptember': 3626,\n",
       " 'Ġomnipotent': 5880,\n",
       " 'Ġsuspense': 4828,\n",
       " 'Ġexplan': 2687,\n",
       " 'Ġhidingplace': 4884,\n",
       " 'af': 3469,\n",
       " 'Ġfarm': 5076,\n",
       " 'ately': 1611,\n",
       " 'og': 4998,\n",
       " 'Ġexceed': 3282,\n",
       " 'cified': 6533,\n",
       " 'iter': 1506,\n",
       " 'iz': 1168,\n",
       " 'ging': 3203,\n",
       " 's': 85,\n",
       " 'fect': 1549,\n",
       " 'ub': 1973,\n",
       " 'ulation': 3582,\n",
       " 'se': 316,\n",
       " 'Ġbecoming': 4898,\n",
       " 'Ġbewildered': 4916,\n",
       " 'Ġhorizon': 3706,\n",
       " 'Ġunworthy': 7507,\n",
       " 'Ġflying': 7198,\n",
       " 'l': 78,\n",
       " 'Ġidle': 5443,\n",
       " 'Ġviews': 5570,\n",
       " 'Ġplan': 2447,\n",
       " 'Ġsagacity': 6448,\n",
       " 'Ġlakes': 3912,\n",
       " 'Ġevidence': 2709,\n",
       " 'Ġhelp': 2185,\n",
       " 'Ġminds': 4048,\n",
       " 'Ġskies': 6955,\n",
       " 'Ġassu': 1994,\n",
       " 'lance': 4324,\n",
       " 'Ġappear': 857,\n",
       " 'Ġsockets': 7621,\n",
       " 'Ġfury': 3507,\n",
       " 'erest': 1166,\n",
       " 'Ġalas': 3585,\n",
       " 'Ġclaim': 2513,\n",
       " 'Ġalso': 792,\n",
       " 'Ġrepugnance': 5950,\n",
       " 'Ġeagle': 7000,\n",
       " 'Ġwishing': 6928,\n",
       " 'Ġrambling': 7237,\n",
       " 'Ġdescend': 2011,\n",
       " 'Ġwhile': 849,\n",
       " 'berland': 5417,\n",
       " 'Ġabod': 3624,\n",
       " 'Ġministers': 7541,\n",
       " 'Ġcalm': 1456,\n",
       " 'Ġwhisp': 3921,\n",
       " 'Ġsnatched': 4913,\n",
       " 'Ġsp': 428,\n",
       " 'utation': 6274,\n",
       " 'Ġwhole': 1232,\n",
       " 'Ġinterest': 1442,\n",
       " 'Ġpresently': 3086,\n",
       " 'such': 2689,\n",
       " 'isions': 6196,\n",
       " 'Ġwalk': 2336,\n",
       " 'antity': 3299,\n",
       " 'ensible': 6663,\n",
       " 'Ġtou': 2984,\n",
       " 'Ġreach': 3544,\n",
       " 'Ġpop': 5114,\n",
       " 'Ġinvisible': 5627,\n",
       " 'Ġworks': 1057,\n",
       " '«': 107,\n",
       " 'Ġunac': 4498,\n",
       " 'Ġgre': 2289,\n",
       " 'Ġobscured': 7171,\n",
       " 'Ġinstruct': 3093,\n",
       " 'ror': 2498,\n",
       " 'irt': 1395,\n",
       " 'Ġmurderer': 1412,\n",
       " 'Ġconsumm': 3417,\n",
       " 'Ġdisplayed': 4833,\n",
       " 'that': 2664,\n",
       " 'Ġwitnesses': 2939,\n",
       " 'Ġcomprehe': 3623,\n",
       " 'Ġforb': 3275,\n",
       " 'Ġanguish': 1585,\n",
       " 'Ġimperfect': 7396,\n",
       " 'Ġears': 3090,\n",
       " 'Ġgermany': 5841,\n",
       " '@': 34,\n",
       " 'Ġdeclined': 3761,\n",
       " 'cend': 1431,\n",
       " 'Ġmatlock': 5583,\n",
       " 'Ġlink': 3263,\n",
       " 'Ġinfinite': 4923,\n",
       " 'isper': 6197,\n",
       " 'Ġcreating': 4035,\n",
       " 'ric': 3845,\n",
       " 'gacity': 6005,\n",
       " 'Ġbenev': 1596,\n",
       " 'Ġeld': 4416,\n",
       " 'Ġbanks': 3184,\n",
       " 'Ġwarr': 3496,\n",
       " 'Ġemployed': 2346,\n",
       " 'Ġdesires': 4000,\n",
       " 'usions': 4529,\n",
       " 'Ġremote': 5326,\n",
       " 'Ġdie': 1528,\n",
       " 'most': 957,\n",
       " 'Ġunwilling': 4279,\n",
       " 'Ġcomplaints': 7444,\n",
       " 'Ġsorrows': 3383,\n",
       " 'Ġprobable': 4816,\n",
       " 'Ġtruly': 4008,\n",
       " 'Ġobsc': 2573,\n",
       " 'Ġyouthful': 5568,\n",
       " 'Ġlights': 6745,\n",
       " 'Ġanxiously': 7291,\n",
       " 'dening': 6812,\n",
       " 'Ġgree': 3931,\n",
       " 'mo': 4992,\n",
       " 'Ġesteemed': 7416,\n",
       " 'Ġmelancholy': 1892,\n",
       " 'Ġwebs': 4454,\n",
       " 'Ġnurse': 2941,\n",
       " 'Ġthrush': 6719,\n",
       " 'Ġreve': 3027,\n",
       " 'Ġcolle': 4710,\n",
       " 'Ġthreats': 4764,\n",
       " 'Ġsurp': 5434,\n",
       " 'Ġexpenses': 7648,\n",
       " 'Ġpartial': 6683,\n",
       " 'Ġheavy': 4865,\n",
       " 'Ġdue': 5100,\n",
       " 'Ģ': 225,\n",
       " 'Ġsmo': 6747,\n",
       " 'Ġcustom': 4890,\n",
       " 'oub': 1169,\n",
       " 'Ġsecure': 2902,\n",
       " 'Ġenchanting': 5818,\n",
       " 'Ġperhaps': 1722,\n",
       " 'Ġgest': 3929,\n",
       " 'ement': 1482,\n",
       " 'Ġprison': 2219,\n",
       " 'app': 949,\n",
       " 'Ġtell': 2626,\n",
       " 'g': 73,\n",
       " 'Ġreading': 4684,\n",
       " '¯': 110,\n",
       " 'Ġforms': 2705,\n",
       " ';': 29,\n",
       " 'Ġgovern': 3179,\n",
       " 'before': 3365,\n",
       " 'veral': 918,\n",
       " 'ċ': 202,\n",
       " 'Ġdwelling': 2761,\n",
       " 'oused': 2999,\n",
       " 'Ġheat': 3024,\n",
       " 'Ġdiscovery': 1867,\n",
       " 'Ġplainpal': 5667,\n",
       " 'Ġbolt': 7484,\n",
       " 'lly': 3537,\n",
       " 'Ġunfortun': 1855,\n",
       " 'Ġrugged': 4300,\n",
       " 'Ġworse': 4510,\n",
       " 'Ġdesiring': 7380,\n",
       " 'assed': 3010,\n",
       " 'enched': 5088,\n",
       " 'Ġtill': 6083,\n",
       " 'Ġfavourable': 3392,\n",
       " 'Ġcountry': 860,\n",
       " 'look': 3206,\n",
       " 'Ġcountenances': 2887,\n",
       " 'Ġhum': 786,\n",
       " 'Ġtong': 6085,\n",
       " 'eas': 877,\n",
       " 'Ġavailable': 7349,\n",
       " 'Ġeither': 3017,\n",
       " 'wich': 6074,\n",
       " 'Ġdirected': 2344,\n",
       " 'Ġreport': 5376,\n",
       " 'Ġuse': 1434,\n",
       " 'Ġprec': 2869,\n",
       " 'lack': 1660,\n",
       " 'Ġcurse': 2892,\n",
       " 'Ġissu': 5243,\n",
       " 'Ġcaptain': 4119,\n",
       " 'Ġsupport': 1947,\n",
       " 'Ġmyself': 560,\n",
       " 'igable': 5359,\n",
       " 'Ġderive': 5812,\n",
       " 'Ġag': 447,\n",
       " 'ered': 470,\n",
       " 'Ġentire': 1573,\n",
       " 'Ġawaken': 6666,\n",
       " 'Ġdisturbed': 3164,\n",
       " 'Ġdiscovering': 5549,\n",
       " 'Ġremoved': 3797,\n",
       " 'gener': 6003,\n",
       " 'Ġbecame': 845,\n",
       " 'Ġmutable': 7128,\n",
       " 'emoney': 6451,\n",
       " 'ailing': 6892,\n",
       " 'Ġbrooded': 6973,\n",
       " 'Ġtasted': 6090,\n",
       " 'Ġdisclaim': 4178,\n",
       " 'Ġcollected': 2732,\n",
       " 'Ġchair': 3604,\n",
       " 'Ġmarvellous': 5505,\n",
       " 'Ġsprung': 7020,\n",
       " 'Ġinconstant': 7339,\n",
       " 'Ġpo': 631,\n",
       " 'Ġsongs': 5887,\n",
       " 'cription': 5472,\n",
       " 'alleled': 4299,\n",
       " 'Ġgiven': 1882,\n",
       " 'op': 474,\n",
       " 'Ġtemp': 3218,\n",
       " 'Ġapparently': 2764,\n",
       " 'Ġacquire': 4693,\n",
       " 'blem': 6588,\n",
       " 'Ġindulged': 5735,\n",
       " 'Ġsong': 4365,\n",
       " 'rest': 3220,\n",
       " 'gular': 6004,\n",
       " 'Ġcharacter': 2946,\n",
       " '6': 24,\n",
       " 'iveness': 4928,\n",
       " 'Ġlistener': 6858,\n",
       " 'et': 342,\n",
       " 'Ġappalling': 3997,\n",
       " 'Ġcoll': 1330,\n",
       " 'Ġforbear': 7274,\n",
       " 'eog': 5992,\n",
       " 'Ġnever': 808,\n",
       " 'Ġtorments': 5467,\n",
       " 'Ġrotter': 6431,\n",
       " 'Ġtherefore': 1128,\n",
       " 'Ġslow': 2759,\n",
       " 'icity': 4425,\n",
       " 'Ġemb': 1943,\n",
       " 'cles': 4050,\n",
       " 'qualities': 6423,\n",
       " 'ission': 2175,\n",
       " 'Ġpresumption': 5387,\n",
       " 'Ġregulate': 6779,\n",
       " 'Ġad': 579,\n",
       " 'Ġthomas': 7592,\n",
       " 'Ġtour': 4349,\n",
       " 'Ġconster': 6345,\n",
       " 'Ġplunged': 5412,\n",
       " 'Ġcompliance': 4555,\n",
       " 'ast': 488,\n",
       " 'Ġgallant': 7366,\n",
       " '¦': 102,\n",
       " 'ance': 476,\n",
       " 'Ġlament': 3536,\n",
       " 'imely': 6599,\n",
       " 'Ġpines': 5117,\n",
       " 'Ġobjects': 2471,\n",
       " 'Ġconvey': 2488,\n",
       " 'Ġbew': 3913,\n",
       " 'to': 1691,\n",
       " 'ached': 1192,\n",
       " 'Ġmean': 1844,\n",
       " 'Ġmid': 2504,\n",
       " 'Ġmuham': 6774,\n",
       " 'orgdon': 7224,\n",
       " 'Ġrenewed': 3768,\n",
       " 'Ġsake': 3057,\n",
       " 'orn': 1836,\n",
       " 'Ġinquired': 4165,\n",
       " 'itive': 3009,\n",
       " 'Ġincludes': 7077,\n",
       " 'ab': 364,\n",
       " 'Ġhorrid': 4123,\n",
       " 'Ġexclaim': 1732,\n",
       " 'Ġties': 3855,\n",
       " 'Ġmassac': 7422,\n",
       " 'Ġworth': 3984,\n",
       " 'Ġpayments': 5793,\n",
       " 'Ġposted': 4834,\n",
       " 'ister': 1225,\n",
       " 'est': 397,\n",
       " 'ff': 427,\n",
       " 'Ġsting': 4459,\n",
       " 'Ġfinding': 3379,\n",
       " 'Ġfees': 4467,\n",
       " 'Ġshuddering': 5808,\n",
       " 'Ġconduct': 1877,\n",
       " 'Ġchimney': 7377,\n",
       " 'Ġfrom': 385,\n",
       " 'ident': 1996,\n",
       " 'Ġnut': 6242,\n",
       " 'Ġshrink': 7371,\n",
       " 'Ġmagnificent': 3182,\n",
       " 'Ġpurpose': 1741,\n",
       " 'Ġlaw': 1322,\n",
       " 'Ġvent': 3045,\n",
       " 'Ġclearly': 5661,\n",
       " 'ipate': 3102,\n",
       " 'Ġdesolated': 7515,\n",
       " 'Ġrelief': 4785,\n",
       " 'Ġshattered': 3954,\n",
       " 'Ġinjury': 4830,\n",
       " 'Ġperceive': 3301,\n",
       " 'aused': 1530,\n",
       " 'Ġinsu': 3910,\n",
       " 'Ĺ': 248,\n",
       " 'Ġlandscape': 5869,\n",
       " 'Ġface': 1726,\n",
       " 'ial': 1817,\n",
       " 'ingp': 3014,\n",
       " 'Ġunconscious': 7667,\n",
       " 'Ġopportunity': 3809,\n",
       " 'ss': 4334,\n",
       " 'Ġcopyright': 2238,\n",
       " 'Ġcous': 1429,\n",
       " 'Ġknees': 7378,\n",
       " 'Ġpains': 3901,\n",
       " 'Ġdelic': 4446,\n",
       " 'Ġcondemn': 4796,\n",
       " 'Ġgrave': 3335,\n",
       " 'nothing': 3802,\n",
       " 'Ġresign': 4030,\n",
       " 'aid': 2052,\n",
       " 'Ġqu': 576,\n",
       " 'Ġmer': 1900,\n",
       " 'Ġsl': 2068,\n",
       " 'Ġrequire': 3699,\n",
       " 'Ġfulfilment': 5740,\n",
       " 'ort': 495,\n",
       " 'Ġhours': 1173,\n",
       " 'resses': 6649,\n",
       " 'Ġsafety': 2728,\n",
       " 'Ġinspirited': 7176,\n",
       " 'Ġtrem': 1251,\n",
       " 'human': 6009,\n",
       " 'Ġplunge': 5410,\n",
       " 'Ġduties': 2587,\n",
       " 'Ġmaj': 3183,\n",
       " 'Ġwelcomed': 4208,\n",
       " 'B': 36,\n",
       " 'Ġvoid': 5460,\n",
       " 'Ġconsume': 5633,\n",
       " 'Ġsoci': 2003,\n",
       " 'Ġmay': 612,\n",
       " 'ature': 2070,\n",
       " 'felt': 4973,\n",
       " 'en': 277,\n",
       " 'Ġice': 1045,\n",
       " 'Ġeditions': 4731,\n",
       " 'ampled': 7236,\n",
       " 'Ġpail': 5116,\n",
       " '`': 66,\n",
       " 'cast': 4308,\n",
       " 'Ġwarranties': 5877,\n",
       " 'Ġunguarded': 7634,\n",
       " ...}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe_tokenizer.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46bb80eb-b9db-4d8e-8921-09a8e68b00af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5Config {\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"transformers_version\": \"4.46.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 20000\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import PretrainedConfig\n",
    "\n",
    "# Create configuration for the tokenizer (for future use)\n",
    "from transformers import T5Config\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "config = T5Config(\n",
    "    vocab_size=20000,                # Set vocab size based on your tokenizer\n",
    "    d_model=768,                     # Embedding size (similar to n_embd in GPT2)\n",
    "    num_layers=12,                   # Number of transformer layers (encoder and decoder)\n",
    "    num_heads=12,                    # Number of attention heads\n",
    "    max_position_embeddings=512,     # Max sequence length   \n",
    "    decoder_start_token_id = tokenizer.pad_token_id,        \n",
    "    pad_token_id = tokenizer.pad_token_id,\n",
    "    eos_token_id = tokenizer.eos_token_id\n",
    ")\n",
    "\n",
    "#model = AutoModelForCausalLM.from_config(config)\n",
    "model = AutoModelForSeq2SeqLM.from_config(config)\n",
    "#model.train()\n",
    "print(config)\n",
    "config.save_pretrained(model_name)\n",
    "# After training, save the model weights and configuration\n",
    "model.save_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86ada377-5284-4b62-ae70-2e130e1dcb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "use_gpu = -1\n",
    "if torch.cuda.is_available():\n",
    "    use_gpu = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5a5ade2-65c5-426a-ab72-04f189fb222c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e9b723c9d984d56bbc8a01b1f38db75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "datasets = load_dataset(\"text\", data_files={\"train\": './shelley_processed.txt'})\n",
    "datasets = datasets[\"train\"].train_test_split(test_size=0.2)\n",
    "train_dataset = datasets['train']\n",
    "eval_dataset = datasets['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3e96a05-3053-4e73-8666-513a67723449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 2474\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(datasets['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19d85465-48ed-4c24-ab11-3c6ad525a4e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "# Use the directory where you saved the tokenizer files\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d2f1b70d-e077-442b-b1d8-d2e38baf1d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce083b05bf3c474ba7139f24d049d2bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2474 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7dd1854925d43f3b36d5f01a22c0fe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/619 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenizer function for multiuse\n",
    "def tokenize(examples):\n",
    "    return tokenizer(examples['text'], padding=True, truncation=True, max_length=30)\n",
    "#Tokenize data \n",
    "tokenized_data = datasets.map(tokenize, batched = True, num_proc = 1, remove_columns = ['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b8e18a7e-bb4e-43ce-8c3c-5e093531169b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [1853, 319, 266, 819, 7486, 14, 266, 819, 5533, 14, 353, 348, 319, 434, 717, 284, 355, 2137, 516, 1171, 282, 5437, 279, 4846, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_data['train'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3c7f7821-4931-4d9f-929f-7233fc32a3d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0a73a6ae1e24367bc14c1987c3437ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2474 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a018a18a9bcb4c2386bcc1bf826de10a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/619 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'! how did i cling to their dear forms, as sometimes they haunted even my waking hours, and persuadethe stars shone at intervals as the clouds passed from over them; the dark pines rose before me, and every here and there a broken tree lay onour house was the house of mourningi lay for two months on the point of death; my ravings, as i afterwards heard, were frightful; i called myself the murderer of william,am i not shunned and hated by all mankind? you, my creator, would'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparams\n",
    "block_size = 128\n",
    "\n",
    "def group_texts(examples):\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "\n",
    "    total_length = (total_length // block_size) * block_size\n",
    "    # Split by chunks of max_len.\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result\n",
    "\n",
    "lm_datasets = tokenized_data.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    batch_size=128,\n",
    "    num_proc=1,\n",
    ")\n",
    "# CHeck that decoder works okay\n",
    "tokenizer.decode(lm_datasets[\"train\"][1][\"input_ids\"], skip_special_tokens = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bdfd494e-f343-48d8-a71c-a4c6a4b7bf76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoModelForSeq2SeqLM\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "#writer = SummaryWriter(\"logs/graphs\")\n",
    "#writer.add_graph(model, lm_datasets[\"train\"][0][\"input_ids\"])\n",
    "#writer.close()\n",
    "\n",
    "print(tokenizer.pad_token_id)\n",
    "print(model.config.pad_token_id)\n",
    "\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "#model_name = model_checkpoint.split(\"/\")[-1]\n",
    "training_args = TrainingArguments(\n",
    "    f\"{model_name}-test\",\n",
    "    per_device_train_batch_size=6,  \n",
    "    gradient_accumulation_steps=8,  \n",
    "    eval_strategy = \"epoch\",\n",
    "    num_train_epochs = 30,\n",
    "    save_total_limit=2,  \n",
    "    learning_rate=0.001,\n",
    "    #weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps = 3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "518d494c-0f34-4e37-8925-1e9e891bdd99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [1221, 1317, 652, 346, 303, 266, 977, 79, 2175, 282, 6552, 4821, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 86, 1164, 332, 387, 539, 5903, 320, 4849, 284, 387, 279, 260, 1363, 282, 2506, 14, 480, 1616, 3277, 332, 355, 5634, 14, 260, 1368, 282, 3653, 14, 353, 438, 1853, 319, 266, 819, 7486, 14, 266, 819, 5533, 14, 353, 348, 319, 434, 717, 284, 355, 2137, 516, 1171, 282, 5437, 279, 4846, 0, 0, 0, 0, 0, 0, 2968, 319, 346, 4770, 6529, 29, 279, 294, 295, 3107, 379, 320, 659, 14, 282, 1105, 5964, 6716, 14, 360, 3438, 6692, 1860, 301, 2056, 85, 1229, 321, 655, 516, 1453, 7280, 7188, 599, 262, 528, 337, 551], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [1221, 1317, 652, 346, 303, 266, 977, 79, 2175, 282, 6552, 4821, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 86, 1164, 332, 387, 539, 5903, 320, 4849, 284, 387, 279, 260, 1363, 282, 2506, 14, 480, 1616, 3277, 332, 355, 5634, 14, 260, 1368, 282, 3653, 14, 353, 438, 1853, 319, 266, 819, 7486, 14, 266, 819, 5533, 14, 353, 348, 319, 434, 717, 284, 355, 2137, 516, 1171, 282, 5437, 279, 4846, 0, 0, 0, 0, 0, 0, 2968, 319, 346, 4770, 6529, 29, 279, 294, 295, 3107, 379, 320, 659, 14, 282, 1105, 5964, 6716, 14, 360, 3438, 6692, 1860, 301, 2056, 85, 1229, 321, 655, 516, 1453, 7280, 7188, 599, 262, 528, 337, 551]}\n"
     ]
    }
   ],
   "source": [
    "print(lm_datasets[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "401e937c-653a-4d1e-879c-dc2de4a2bbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=lm_datasets[\"train\"],\n",
    "    eval_dataset=lm_datasets[\"test\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dcdbb99f-c3b0-47af-8dc0-9f506b5d9117",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='360' max='360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [360/360 04:45, Epoch 29/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7.112400</td>\n",
       "      <td>6.637514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6.205400</td>\n",
       "      <td>6.048180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5.808700</td>\n",
       "      <td>5.820285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5.615200</td>\n",
       "      <td>5.612189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.406300</td>\n",
       "      <td>5.438526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5.294300</td>\n",
       "      <td>5.315340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>5.182300</td>\n",
       "      <td>5.220170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>4.976700</td>\n",
       "      <td>5.076432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>5.014000</td>\n",
       "      <td>5.029024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4.986600</td>\n",
       "      <td>4.986720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>4.770600</td>\n",
       "      <td>4.951241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>4.775600</td>\n",
       "      <td>4.929831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>4.837400</td>\n",
       "      <td>4.904223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>4.721300</td>\n",
       "      <td>4.894419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>4.645500</td>\n",
       "      <td>4.859488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>4.623100</td>\n",
       "      <td>4.852073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>4.695300</td>\n",
       "      <td>4.846267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>4.604900</td>\n",
       "      <td>4.845217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>4.605300</td>\n",
       "      <td>4.837254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>4.579800</td>\n",
       "      <td>4.840125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>4.468200</td>\n",
       "      <td>4.838441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>4.453400</td>\n",
       "      <td>4.832462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>4.509700</td>\n",
       "      <td>4.827346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>4.451000</td>\n",
       "      <td>4.825829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>4.529600</td>\n",
       "      <td>4.825735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>4.403300</td>\n",
       "      <td>4.827106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>4.554800</td>\n",
       "      <td>4.825621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 56s, sys: 49.4 s, total: 4min 46s\n",
      "Wall time: 4min 46s\n"
     ]
    }
   ],
   "source": [
    "%time training_out = trainer.train()\n",
    "trainer.save_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6968bfb2-f765-4320-9894-516f7b72d362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1c80317fa3b1799d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1c80317fa3b1799d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b96b70ed-f79e-401a-9168-cb556b8e3e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Create models from trained model\n",
    "s_model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "s_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "print(s_model.config.pad_token_id)\n",
    "#print(s_tokenizer.pad_token_id)\n",
    "#s_tokenizer.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "67d32f3a-fee3-4143-9228-1b82e84e157c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 833,  459, 3919,  584]])\n"
     ]
    }
   ],
   "source": [
    "#Txt gen attempr\n",
    "\n",
    "prompt = 'you will rejoice'\n",
    "\n",
    "input_ids = tokenizer(prompt, return_tensors='pt').input_ids\n",
    "print(input_ids)\n",
    "# model generate with causal lm  = Text generation\n",
    "#decoder_input_ids = tokenizer(\"<pad>\", add_special_tokens=False, return_tensors=\"pt\").input_ids\n",
    "\n",
    "#print(input_ids['attention_mask'])\n",
    "#e_outputs = s_model(input_ids, decoder_input_ids = decoder_input_ids, return_dict=True)\n",
    "#encoded_seq = (e_outputs.encoder_last_hidden_state,)\n",
    "#print(encoded_seq)\n",
    "#print(e_outputs.logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8ca8f01a-c806-42bb-b715-c25c0159a96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   0,    0,   75,  341,  489,  279,  319,  284,  321,   14,  262,  395,\n",
      "          489,  346,  303,  266,  888,  266,  687,  888,  429,   14,  279,  266,\n",
      "          937,   14,  352,  262,  341,  695,  489,  282,  266,  672,   29,  262,\n",
      "          319,  266,  279,  295,  686,   14,  295,  782,  284,  266,  819,  260,\n",
      "          880,  321,    0,  396,  819,  562,   29,  266,  559,    0,  261,   14,\n",
      "          353,  262,  673,  437,    0,  592,  562,   14,  266, 1407,  303,  260,\n",
      "          616,  282,  295,  562,  319,  260, 1297,  266,  978,  282,  387,   14,\n",
      "          425,  266,  829,    0,  289,  399,  346,  320,  306,  319,   14,  337,\n",
      "          266,  754,  578,  266, 1526,  282,  260,  837,  319,  535,   14,  345,\n",
      "          266, 1089,  262,  457,  535,  319,  355,   14,  320,  262,  485,  346,\n",
      "           14,  284,  360,  606,    0,  505,  262,  599,  262,  740,  266, 1015,\n",
      "            0, 1183,  303,  321,  279,  360,  639,  282,  393,   14,  438,  319,\n",
      "          346,    0,  909,  262,  459,  262,  590,  303,   14,  306,  648,  260,\n",
      "          429,    0,  534,  341,  549,  322,   14,  294,  295,  685,   14,  332,\n",
      "          352,  306,  341,  486,  562,  337,  260,  516,  573,  348,  399,  284,\n",
      "          303,  437,   14,  282,  360,  562,  341, 1581,  295,  606,  282,  422,\n",
      "           14,  374,  266,  319,  379,  260,  824,  282,  589,  395, 1195,  374,\n",
      "          260,  713,  262,  494,  346,  284,  295,  639,   14,  433,  295,  565,\n",
      "           14,  260]])\n",
      "you will rejoice i had been and was to me, i have been not be the old the most old man, and the cottage, which i had ever been of the night; i was the and my heart, my dear to the same a little methe same father; the dayhe, but i saw himmy father, the greatest be a great of my father was a thousand the world of her, when the sunit is not that he was, for the very upon the door of a few was now, as the fiend i am now was an, that i could not, to his ownbut i did i felt the scenethey be me and his eyes of this, who was notwhen i will i might be, he said a manwe had before you, in my mind, with which he had no father for a more than it is to be him, of his father had destroyed my own of your, by the was at a child of its have taken by a long i do not to my eyes, or my friend, a\n"
     ]
    }
   ],
   "source": [
    "outputs = s_model.generate(\n",
    "    input_ids,\n",
    "    # Gen text len\n",
    "    max_length=218,           \n",
    "    num_return_sequences=1,\n",
    "    # Sampling should be true if using top_k or top_p word estimeation if false use greedy methods\n",
    "    do_sample=True,\n",
    "    top_k=5,\n",
    "    top_p=0.95,\n",
    "    no_repeat_ngram_size=2,\n",
    "    pad_token_id=s_tokenizer.pad_token_id, \n",
    "    eos_token_id=s_tokenizer.eos_token_id,\n",
    "    decoder_start_token_id=s_tokenizer.pad_token_id,\n",
    "    # Set temp for less random gen\n",
    "    temperature=1.0\n",
    ")\n",
    "print(outputs)\n",
    "generated_text = s_tokenizer.decode(outputs[0] , skip_special_tokens = True)\n",
    "full_output = prompt + \" \" + generated_text\n",
    "print(full_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "b0dc3819-d927-4239-ad5a-fb5d33d0c339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you will rejoice  the most of the same of my own own of a few, and i had been the cottage, but i was a littlei had taken to the world to me, i have been a manthe most great and the night, the murderer of his father, which i am the sun had not to be the old man, my fathermy father was the greatest of this time, as a thousand man and my heart, for the day, when i could not the first been to my eyesbut i saw the door of her own father and a great, that i should be a long of your father had no great was very greathe was to you are not be my friend, in the lake, to a new and then, with the ground, he had already been my mind and in a childit was in my dear not so long and he was now and to her, who had hitherto been, a very very man; and, yet i felt the idea of which, although i can not know, of its father is, or the morning\n"
     ]
    }
   ],
   "source": [
    "\n",
    "greedy_search_outputs = s_model.generate(\n",
    "    input_ids,\n",
    "    # Gen text len\n",
    "    max_length=218,           \n",
    "    num_return_sequences=1,\n",
    "    no_repeat_ngram_size=2,\n",
    "    #temperature=0.7,\n",
    ")\n",
    "\n",
    "\n",
    "generated_text = s_tokenizer.decode(greedy_search_outputs[0], skip_special_tokens=True)\n",
    "greedy_output = prompt + \" \" + generated_text\n",
    "print(greedy_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "9f537cdf-35fe-4b72-8ce8-71f52bddc369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you will rejoice  of the most of my father, and i had been the cottage, but i have been been a man, i could not to me; but it is a fewi had taken me, which i am not be my heart of his eyes, as i saw, for ever i shall be the world, when i should be a little, that i was to you will be me to the night, in the same other; and my eyes of this was in my friend, with the murderer of your father was a thousand time, he had already one of which he was not so long of her mother; i did not know, who, my mind and the old man; it was the day, although i can not yet you are to be him, to my own eyes and then i felt me with me in a great and when he is the first saw me from the sun had no other time; my mother, yet i might be all, or to her eyes was now at the idea of a child and in this, the door, however, while i thought of\n"
     ]
    }
   ],
   "source": [
    "beam_search_outputs = s_model.generate(\n",
    "    input_ids,\n",
    "    # Gen text len\n",
    "    max_length=218,           \n",
    "    num_return_sequences=1,\n",
    "    no_repeat_ngram_size=2,\n",
    "    num_beams = 5,\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "\n",
    "generated_text = s_tokenizer.decode(beam_search_outputs[0], skip_special_tokens=True)\n",
    "beam_output = prompt + \" \" + generated_text\n",
    "print(beam_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c051b514-49cf-4f04-9ca1-0abe4dd2f699",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
