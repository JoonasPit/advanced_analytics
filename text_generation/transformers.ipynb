{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3da5832e-69e5-440d-b6ad-b584d79935fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-21 08:12:51.694507: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-21 08:12:51.703678: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1732169571.715038    7775 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1732169571.718353    7775 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-21 08:12:51.729926: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from urllib import request\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from io import StringIO\n",
    "from collections import Counter\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "import nltk\n",
    "from __future__ import print_function\n",
    "from keras.layers import Dense, Activation, SimpleRNN, LSTM\n",
    "from keras.models import Sequential\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import wordcloud as w\n",
    "import matplotlib.pyplot as plot\n",
    "import torch\n",
    "from transformers import  BartTokenizer, TFBartForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8315135-1231-4296-89ce-db618b8a38de",
   "metadata": {},
   "outputs": [],
   "source": [
    "shelley_frank = request.urlopen('https://www.gutenberg.org/cache/epub/84/pg84.txt').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32edb3cc-6664-47d5-860b-5e3548b2e2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Project Gutenberg eBook of Frankenstein; Or, The Modern Prometheus\n",
      "    \n",
      "This ebook is for the \n"
     ]
    }
   ],
   "source": [
    "shelley_frank = shelley_frank.decode('utf-8-sig')\n",
    "print(shelley_frank[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09e85a4f-09df-47b1-8f97-202a9c378970",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_start = 'You will rejoice'\n",
    "word_index = shelley_frank.find(actual_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e288336b-6c18-46e3-8782-c66115e02a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if word_index != -1:\n",
    "    shelley_frank = shelley_frank[word_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8b0754c-d990-4d5c-b383-fdcbf10c450c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you will rejoice to hear that no disaster has accompanied the commencement of an enterprise which yo\n"
     ]
    }
   ],
   "source": [
    "shelley_frank = re.sub(r'—', ' ', shelley_frank.lower())\n",
    "shelley_frank = shelley_frank.replace('project gutenberg', '')\n",
    "shelley_frank = nltk.word_tokenize(shelley_frank)\n",
    "shelley_frank = ' '.join(shelley_frank)  \n",
    "\n",
    "# Ensure space after punctuation if it's missing\n",
    "print(shelley_frank[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7976306-1b83-4e23-b136-d0679c13a91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you will rejoice to hear that no disaster has accompanied the commencement of an enterprise which you have regarded with such evil forebodings. i arrived here yesterday, and my first task is to assure my dear sister of my welfare and increasing confidence in the success of my undertaking. i am already far north of london, and as i walk in the streets of petersburgh, i feel a cold northern breeze play upon my cheeks, which braces my nerves and fills me with delight. do you understand this feeling? this breeze, which has travelled from the regions towards which i am advancing, gives me a foretaste of those icy climes. inspirited by this wind of promise, my daydreams become more fervent and vivid. i try in vain to be persuaded that the pole is the seat of frost and desolation; it ever presents itself to my imagination as the region of beauty and delight. there, margaret, the sun is for ever visible, its broad disk just skirting the horizon and diffusing a perpetual splendour. there for wi\n"
     ]
    }
   ],
   "source": [
    "shelley_frank = re.sub(r'[^a-zA-Z.,!?; ]', '', shelley_frank)\n",
    "shelley_frank = re.sub(r'([.,!?;])', r'\\1 ', shelley_frank)\n",
    "shelley_frank = re.sub(r'\\s+([.,!?;])', r'\\1', shelley_frank)\n",
    "shelley_frank = re.sub(r'\\s+', ' ', shelley_frank) \n",
    "print(shelley_frank[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "740019aa-d2ad-4797-a25d-2fea45c70cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./shelley.txt', 'w') as output_file:\n",
    "    output_file.write(shelley_frank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "385313f2-e52a-4ba7-9f30-eff4003b581a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "CPU times: user 1.36 s, sys: 441 ms, total: 1.8 s\n",
      "Wall time: 263 ms\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import ByteLevelBPETokenizer\n",
    "from tokenizers.implementations import ByteLevelBPETokenizer\n",
    "from tokenizers.processors import BertProcessing\n",
    "\n",
    "bpe_tokenizer = ByteLevelBPETokenizer()\n",
    "\n",
    "%time bpe_tokenizer.train(files='./shelley.txt', vocab_size=20000, min_frequency=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b20fc978-12b0-472e-be6d-e06eba0db574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘./transf_shelley’: File exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./transf_shelley/vocab.json', './transf_shelley/merges.txt']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!mkdir ./transf_shelley\n",
    "model_name = './transf_shelley'\n",
    "bpe_tokenizer.save_model('./transf_shelley')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "86ada377-5284-4b62-ae70-2e130e1dcb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "use_gpu = -1\n",
    "if torch.cuda.is_available():\n",
    "    use_gpu = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b5a5ade2-65c5-426a-ab72-04f189fb222c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "datasets = load_dataset(\"text\", data_files={\"train\": './shelley.txt'})\n",
    "#model_checkpoint = 'stabilityai/stablelm-zephyr-3b'\n",
    "model_checkpoint = model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3e96a05-3053-4e73-8666-513a67723449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 1\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "19d85465-48ed-4c24-ab11-3c6ad525a4e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unrecognized model in ./transf_shelley. Should have a `model_type` key in its config.json, or contain one of the following strings in its name: albert, align, altclip, audio-spectrogram-transformer, autoformer, bark, bart, beit, bert, bert-generation, big_bird, bigbird_pegasus, biogpt, bit, blenderbot, blenderbot-small, blip, blip-2, bloom, bridgetower, bros, camembert, canine, chameleon, chinese_clip, chinese_clip_vision_model, clap, clip, clip_text_model, clip_vision_model, clipseg, clvp, code_llama, codegen, cohere, conditional_detr, convbert, convnext, convnextv2, cpmant, ctrl, cvt, dac, data2vec-audio, data2vec-text, data2vec-vision, dbrx, deberta, deberta-v2, decision_transformer, deformable_detr, deit, depth_anything, deta, detr, dinat, dinov2, distilbert, donut-swin, dpr, dpt, efficientformer, efficientnet, electra, encodec, encoder-decoder, ernie, ernie_m, esm, falcon, falcon_mamba, fastspeech2_conformer, flaubert, flava, fnet, focalnet, fsmt, funnel, fuyu, gemma, gemma2, git, glm, glpn, gpt-sw3, gpt2, gpt_bigcode, gpt_neo, gpt_neox, gpt_neox_japanese, gptj, gptsan-japanese, granite, granitemoe, graphormer, grounding-dino, groupvit, hiera, hubert, ibert, idefics, idefics2, idefics3, imagegpt, informer, instructblip, instructblipvideo, jamba, jetmoe, jukebox, kosmos-2, layoutlm, layoutlmv2, layoutlmv3, led, levit, lilt, llama, llava, llava_next, llava_next_video, llava_onevision, longformer, longt5, luke, lxmert, m2m_100, mamba, mamba2, marian, markuplm, mask2former, maskformer, maskformer-swin, mbart, mctct, mega, megatron-bert, mgp-str, mimi, mistral, mixtral, mllama, mobilebert, mobilenet_v1, mobilenet_v2, mobilevit, mobilevitv2, moshi, mpnet, mpt, mra, mt5, musicgen, musicgen_melody, mvp, nat, nemotron, nezha, nllb-moe, nougat, nystromformer, olmo, olmoe, omdet-turbo, oneformer, open-llama, openai-gpt, opt, owlv2, owlvit, paligemma, patchtsmixer, patchtst, pegasus, pegasus_x, perceiver, persimmon, phi, phi3, phimoe, pix2struct, pixtral, plbart, poolformer, pop2piano, prophetnet, pvt, pvt_v2, qdqbert, qwen2, qwen2_audio, qwen2_audio_encoder, qwen2_moe, qwen2_vl, rag, realm, recurrent_gemma, reformer, regnet, rembert, resnet, retribert, roberta, roberta-prelayernorm, roc_bert, roformer, rt_detr, rt_detr_resnet, rwkv, sam, seamless_m4t, seamless_m4t_v2, segformer, seggpt, sew, sew-d, siglip, siglip_vision_model, speech-encoder-decoder, speech_to_text, speech_to_text_2, speecht5, splinter, squeezebert, stablelm, starcoder2, superpoint, swiftformer, swin, swin2sr, swinv2, switch_transformers, t5, table-transformer, tapas, time_series_transformer, timesformer, timm_backbone, trajectory_transformer, transfo-xl, trocr, tvlt, tvp, udop, umt5, unispeech, unispeech-sat, univnet, upernet, van, video_llava, videomae, vilt, vipllava, vision-encoder-decoder, vision-text-dual-encoder, visual_bert, vit, vit_hybrid, vit_mae, vit_msn, vitdet, vitmatte, vits, vivit, wav2vec2, wav2vec2-bert, wav2vec2-conformer, wavlm, whisper, xclip, xglm, xlm, xlm-prophetnet, xlm-roberta, xlm-roberta-xl, xlnet, xmod, yolos, yoso, zamba, zoedepth",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer\n\u001b[0;32m----> 3\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_checkpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_fast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:877\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    875\u001b[0m         config \u001b[38;5;241m=\u001b[39m AutoConfig\u001b[38;5;241m.\u001b[39mfor_model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig_dict)\n\u001b[1;32m    876\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 877\u001b[0m         config \u001b[38;5;241m=\u001b[39m \u001b[43mAutoConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m config_tokenizer_class \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mtokenizer_class\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutoTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mauto_map:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py:1049\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m pattern \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(pretrained_model_name_or_path):\n\u001b[1;32m   1047\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m CONFIG_MAPPING[pattern]\u001b[38;5;241m.\u001b[39mfrom_dict(config_dict, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwargs)\n\u001b[0;32m-> 1049\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1050\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized model in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1051\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould have a `model_type` key in its \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCONFIG_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, or contain one of the following strings \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1052\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min its name: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(CONFIG_MAPPING\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1053\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: Unrecognized model in ./transf_shelley. Should have a `model_type` key in its config.json, or contain one of the following strings in its name: albert, align, altclip, audio-spectrogram-transformer, autoformer, bark, bart, beit, bert, bert-generation, big_bird, bigbird_pegasus, biogpt, bit, blenderbot, blenderbot-small, blip, blip-2, bloom, bridgetower, bros, camembert, canine, chameleon, chinese_clip, chinese_clip_vision_model, clap, clip, clip_text_model, clip_vision_model, clipseg, clvp, code_llama, codegen, cohere, conditional_detr, convbert, convnext, convnextv2, cpmant, ctrl, cvt, dac, data2vec-audio, data2vec-text, data2vec-vision, dbrx, deberta, deberta-v2, decision_transformer, deformable_detr, deit, depth_anything, deta, detr, dinat, dinov2, distilbert, donut-swin, dpr, dpt, efficientformer, efficientnet, electra, encodec, encoder-decoder, ernie, ernie_m, esm, falcon, falcon_mamba, fastspeech2_conformer, flaubert, flava, fnet, focalnet, fsmt, funnel, fuyu, gemma, gemma2, git, glm, glpn, gpt-sw3, gpt2, gpt_bigcode, gpt_neo, gpt_neox, gpt_neox_japanese, gptj, gptsan-japanese, granite, granitemoe, graphormer, grounding-dino, groupvit, hiera, hubert, ibert, idefics, idefics2, idefics3, imagegpt, informer, instructblip, instructblipvideo, jamba, jetmoe, jukebox, kosmos-2, layoutlm, layoutlmv2, layoutlmv3, led, levit, lilt, llama, llava, llava_next, llava_next_video, llava_onevision, longformer, longt5, luke, lxmert, m2m_100, mamba, mamba2, marian, markuplm, mask2former, maskformer, maskformer-swin, mbart, mctct, mega, megatron-bert, mgp-str, mimi, mistral, mixtral, mllama, mobilebert, mobilenet_v1, mobilenet_v2, mobilevit, mobilevitv2, moshi, mpnet, mpt, mra, mt5, musicgen, musicgen_melody, mvp, nat, nemotron, nezha, nllb-moe, nougat, nystromformer, olmo, olmoe, omdet-turbo, oneformer, open-llama, openai-gpt, opt, owlv2, owlvit, paligemma, patchtsmixer, patchtst, pegasus, pegasus_x, perceiver, persimmon, phi, phi3, phimoe, pix2struct, pixtral, plbart, poolformer, pop2piano, prophetnet, pvt, pvt_v2, qdqbert, qwen2, qwen2_audio, qwen2_audio_encoder, qwen2_moe, qwen2_vl, rag, realm, recurrent_gemma, reformer, regnet, rembert, resnet, retribert, roberta, roberta-prelayernorm, roc_bert, roformer, rt_detr, rt_detr_resnet, rwkv, sam, seamless_m4t, seamless_m4t_v2, segformer, seggpt, sew, sew-d, siglip, siglip_vision_model, speech-encoder-decoder, speech_to_text, speech_to_text_2, speecht5, splinter, squeezebert, stablelm, starcoder2, superpoint, swiftformer, swin, swin2sr, swinv2, switch_transformers, t5, table-transformer, tapas, time_series_transformer, timesformer, timm_backbone, trajectory_transformer, transfo-xl, trocr, tvlt, tvp, udop, umt5, unispeech, unispeech-sat, univnet, upernet, van, video_llava, videomae, vilt, vipllava, vision-encoder-decoder, vision-text-dual-encoder, visual_bert, vit, vit_hybrid, vit_mae, vit_msn, vitdet, vitmatte, vits, vivit, wav2vec2, wav2vec2-bert, wav2vec2-conformer, wavlm, whisper, xclip, xglm, xlm, xlm-prophetnet, xlm-roberta, xlm-roberta-xl, xlnet, xmod, yolos, yoso, zamba, zoedepth"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdf4270-b2cf-4342-9d8f-ccef76777e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(examples):\n",
    "    return tokenizer(examples['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f1b70d-e077-442b-b1d8-d2e38baf1d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_data = datasets.map(tokenize, batched = True, num_proc = 1, remove_columns = ['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1937702-d531-47f0-9fca-c4234a2cc991",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_data['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7f7821-4931-4d9f-929f-7233fc32a3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparams\n",
    "block_size = 128\n",
    "\n",
    "def group_texts(examples):\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "        # customize this part to your needs.\n",
    "    total_length = (total_length // block_size) * block_size\n",
    "    # Split by chunks of max_len.\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result\n",
    "\n",
    "lm_datasets = tokenized_data.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    batch_size=1000,\n",
    "    num_proc=1,\n",
    ")\n",
    "\n",
    "tokenizer.decode(lm_datasets[\"train\"][1][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfd494e-f343-48d8-a71c-a4c6a4b7bf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "model = AutoModelForCausalLM.from_pretrained(model_checkpoint)\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "training_args = TrainingArguments(\n",
    "    f\"{model_name}-test\",\n",
    "     per_device_train_batch_size=2,  # Lower the batch size\n",
    "    gradient_accumulation_steps=4,  # Accumulate gradients to simulate larger batch\n",
    "    #evaluation_strategy = \"epoch\",\n",
    "    num_train_epochs = 20,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    #push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401e937c-653a-4d1e-879c-dc2de4a2bbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=lm_datasets[\"train\"],\n",
    "    #eval_dataset=lm_datasets[\"validation\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdbb99f-c3b0-47af-8dc0-9f506b5d9117",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('tuned-shelley')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96b70ed-f79e-401a-9168-cb556b8e3e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "s_model = AutoModelForCausalLM.from_pretrained(\"tuned-shelley\")\n",
    "s_tokenizer = AutoTokenizer.from_pretrained(\"./shelley_safe\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d32f3a-fee3-4143-9228-1b82e84e157c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Txt gen attempr\n",
    "\n",
    "prompt = 'you will rejoice'\n",
    "\n",
    "input_ids = s_tokenizer(prompt, return_tensors='pt').input_ids\n",
    "\n",
    "outputs = s_model.generate(\n",
    "    input_ids,\n",
    "    max_length=512,           # Maximum length of generated text\n",
    "    num_return_sequences=1,  # Number of generated sequences\n",
    "    do_sample=True,          # Use sampling instead of greedy decoding\n",
    "    top_k=5,                # Use top-k sampling\n",
    "    #top_p=0.95,              # Use nucleus sampling\n",
    "    temperature=1.0,         # Control randomness\n",
    ")\n",
    "\n",
    "\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(generated_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
